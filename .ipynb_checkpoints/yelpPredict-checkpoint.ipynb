{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gFh_Duluavim"
   },
   "source": [
    "# BERT for yelp prediction\n",
    "Recall our goals: 1). Find what attributes are ``important'' in sentiment analysis; 2). Predict ratings based on features.\n",
    "Adapted from\n",
    "https://towardsdatascience.com/bert-for-dummies-step-by-step-tutorial-fb90890ffe03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_3Ryo60ccNg"
   },
   "source": [
    "# Preprocessing\n",
    "We preprocess data into numpy format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6UcwFNGtciSA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class data:\n",
    "    def __init__(self, fileName):\n",
    "        df = pd.read_csv(fileName)\n",
    "        values = df.values\n",
    "        # Star ratings, notice for test/validation data, these are actually ids\n",
    "        self.stars = np.array(values[:, 0], dtype = int)\n",
    "        # Name of restaurants\n",
    "        self.names = values[:, 1]\n",
    "        # Text of review\n",
    "        self.text = values[:, 2]\n",
    "        # Date of review\n",
    "        self.date = values[:, 3]\n",
    "        # City of restaurant\n",
    "        self.city = values[:, 7]\n",
    "        # Misc categories, might not use it\n",
    "        self.category = values[:, 10]\n",
    "        # Sentiment score\n",
    "        self.sentiment = np.nan_to_num(values[:, 13])\n",
    "        s = {0, 1, 2, 3, 7, 10}\n",
    "        cols = []\n",
    "        for i in range(values.shape[1]):\n",
    "            if i not in s: cols.append(i)\n",
    "        # Other numerical measurements\n",
    "        self.numerical = np.array(values[:, cols], dtype = np.float64)\n",
    "        self.text_df = None\n",
    "    \n",
    "    def center(self):\n",
    "        # Center all numerical attributes to mean 0\n",
    "        mean = np.nanmean(self.numerical, axis = 0)\n",
    "        self.numerical -= mean\n",
    "        self.numerical = np.nan_to_num(self.numerical)\n",
    "\n",
    "    '''def transfer_text(self):\n",
    "        self.text_df = pd.DataFrame({\n",
    "            \"id\": range(len(self.text)),\n",
    "            \"label\": self.stars,\n",
    "            \"alpha\": [\"a\"] * len(self.text),\n",
    "            \"text\": self.text\n",
    "        })\n",
    "        self.text_df[\"text\"] = self.text_df[\"text\"].replace(r\"\\n\", \" \", regex = True)'''\n",
    "\n",
    "    \n",
    "\n",
    "train_data = data(\"Yelp_train.csv\")\n",
    "validation_data = data(\"Yelp_validate.csv\")\n",
    "test_data = data(\"Yelp_test.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6nrFGF95e5gx"
   },
   "source": [
    "# Setup BERT\n",
    "Here we import all modules BERT needs, preprocess text data into desired\n",
    "format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "id": "gP7Att6ifJ7h",
    "outputId": "a2d31dfc-861c-4238-92c4-90c472841bd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.7/site-packages (0.6.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/site-packages (from pytorch_pretrained_bert) (4.39.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/site-packages (from pytorch_pretrained_bert) (1.10.28)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/site-packages (from pytorch_pretrained_bert) (1.3.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from pytorch_pretrained_bert) (1.17.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/site-packages (from pytorch_pretrained_bert) (2.22.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.7/site-packages (from pytorch_pretrained_bert) (2019.11.1)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.28 in /usr/local/lib/python3.7/site-packages (from boto3->pytorch_pretrained_bert) (1.13.28)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.7/site-packages (from boto3->pytorch_pretrained_bert) (0.2.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/site-packages (from boto3->pytorch_pretrained_bert) (0.9.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests->pytorch_pretrained_bert) (1.25.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests->pytorch_pretrained_bert) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests->pytorch_pretrained_bert) (2.8)\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.7/site-packages (from botocore<1.14.0,>=1.13.28->boto3->pytorch_pretrained_bert) (2.8.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.7/site-packages (from botocore<1.14.0,>=1.13.28->boto3->pytorch_pretrained_bert) (0.15.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.28->boto3->pytorch_pretrained_bert) (1.13.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\nn_gpu = torch.cuda.device_count()\\ntorch.cuda.get_device_name(0)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip3 install pytorch_pretrained_bert\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "'''device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tGSTOmEhP63P"
   },
   "outputs": [],
   "source": [
    "# Add proper prefix/suffix to each sentence\n",
    "sentences = [\"[CLS] \" + text + \" [SEP]\" for text in train_data.text]\n",
    "# Initialize tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\", do_lower_case = False)\n",
    "# Tokenize each sentence with respect to BERT vocabulary\n",
    "tokenized_text = [tokenizer.tokenize(sent) for sent in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HLfSLoP23x74"
   },
   "outputs": [],
   "source": [
    "# Convert all sequences to BERT ids\n",
    "# NOTE: BERT has a maximum sequence length of 512, so many review texts have\n",
    "# been truncated\n",
    "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_text],\n",
    "                          maxlen = 512, dtype = \"long\", truncating = \"post\", padding = \"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MR4WMK0L9rKy"
   },
   "outputs": [],
   "source": [
    "# Attention masks for BERT, in our case, we wish to predict all words, so no \n",
    "# mask needed\n",
    "attentions = []\n",
    "for seq in input_ids:\n",
    "  attentions.append([float(i > 0) for i in seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hdm34z_48B8c"
   },
   "outputs": [],
   "source": [
    "# Split training and validation data 8:2\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, train_data.stars, random_state = 2019,\n",
    "                                                                                    test_size = 0.2)\n",
    "train_masks, validation_masks, _, _ = train_test_split(attentions, input_ids, random_state = 2019, test_size = 0.2)\n",
    "\n",
    "# Turn all data into tensors\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "# Set up iterators for tensors\n",
    "batch_size = 16\n",
    "train_tensor = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "validation_tensor = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "train_sampler = RandomSampler(train_tensor)\n",
    "validation_sampler = SequentialSampler(validation_tensor)\n",
    "train_dataloader = DataLoader(train_tensor, sampler = train_sampler, batch_size = batch_size)\n",
    "validation_dataloader = DataLoader(validation_tensor, sampler = validation_sampler,\n",
    "                                   batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FPKC2JuhhH1F"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aAdfCwopBbuf"
   },
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels = 5)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D47aUT5UDP9-"
   },
   "outputs": [],
   "source": [
    "parameters = list(model.named_parameters())\n",
    "no_decay = [\"bias\", \"gamma\", \"beta\"]\n",
    "grouped_paras = [\n",
    "                 {\"params\": [p for n, p in parameters if not any(nd in n for nd in no_decay)],\n",
    "                  \"weight_decay_rate\": 0.01},\n",
    "                 {\"params\": [p for n, p in parameters if any(nd in n for nd in no_decay)],\n",
    "                  \"weight_decay_rate\": 0.0}\n",
    "]\n",
    "\n",
    "def calc_acc(preds, labels):\n",
    "  pred_flatten = np.argmax(preds, axis = 1).flatten()\n",
    "  labels_flatten = labels.flatten()\n",
    "  return np.sum(pred_flatten == labels_flatten) / len(labels.flatten)\n",
    "\n",
    "\n",
    "optimizer = BertAdam(grouped_paras, lr = 3e-5, warmup = 0.01)\n",
    "\n",
    "train_loss_list = []\n",
    "epochs = 4\n",
    "\n",
    "for _ in trange(epochs, desc = \"Epoch\"):\n",
    "  model.train()\n",
    "  train_loss = 0\n",
    "  number_train_examples, number_train_steps = 0, 0\n",
    "  for step, batch in enumerate(train_dataloader):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_masks, b_labels = batch\n",
    "    optimizer.zero_grad()\n",
    "    loss = model(b_input_ids, token_type_ids = None, attention_mask = b_masks,\n",
    "                 labels = b_labels)\n",
    "    train_loss_list.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss += loss.item()\n",
    "    number_train_examples += b_input_ids.size(0)\n",
    "    number_train_steps += 1\n",
    "\n",
    "  model.eval()\n",
    "  eval_loss, eval_acc = 0, 0\n",
    "  number_eval_examples, number_eval_steps = 0, 0\n",
    "  for batch in validation_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_masks, b_labels = batch\n",
    "    with torch.no_grad():\n",
    "      logits = model(b_input_ids, token_type_ids = None, attention_mask = b_masks)\n",
    "      logits = logits.detach().cpu().numpy()\n",
    "      label_ids = b_labels.to('cpu').numpy()\n",
    "      tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "      eval_acc += tmp_eval_accuracy\n",
    "      number_eval_steps += 1\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "yelpPredict.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
